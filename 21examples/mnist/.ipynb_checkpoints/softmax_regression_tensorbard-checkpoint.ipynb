{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0810 12:53:52.809888 140653173012288 deprecation.py:323] From <ipython-input-2-40e568dce0e4>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "W0810 12:53:52.811517 140653173012288 deprecation.py:323] From /home/aily/py3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "W0810 12:53:52.812355 140653173012288 deprecation.py:323] From /home/aily/py3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/aily/shitao/traindata/mnist/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0810 12:53:53.034120 140653173012288 deprecation.py:323] From /home/aily/py3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "W0810 12:53:53.036418 140653173012288 deprecation.py:323] From /home/aily/py3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "W0810 12:53:53.077685 140653173012288 deprecation.py:323] From /home/aily/py3/lib/python3.7/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /home/aily/shitao/traindata/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /home/aily/shitao/traindata/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /home/aily/shitao/traindata/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "save_dir = '/home/aily/shitao/traindata/mnist'\n",
    "if os.path.exists(save_dir) is False:\n",
    "    os.mkdirs(save_dir)\n",
    "mnist = input_data.read_data_sets(save_dir, one_hot=True)\n",
    "n_batch = mnist.train.num_examples // 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 命名空间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('input'):\n",
    "    #定义变量\n",
    "    # 创建x, x是一个占位符(placeHolder),代表待识别的图片,等使用的时候才加载，分配空间。\n",
    "    x = tf.placeholder(tf.float32, [None, 784], name = 'x_input')\n",
    "    # y_是实际的图像标签，同样以占位符表示\n",
    "    y_ = tf.placeholder(tf.float32, [None, 10], name = 'y_input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. 设定变量\n",
    " - 占位符(placeholder)和变量(Variable)都是tensor,其并不是具体的数值，只是一些我们希望计算的节点\n",
    " - 占位符不依赖其他tensor直接由用户传递，通常用来存储样本数据和标签\n",
    " - 变量是在计算过程中可以改变的值，每次计算后变量的值都会保存下来，一般用于存储模型参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.name_scope('layer'):\n",
    "    with tf.name_scope('weights'):\n",
    "        #w是参数模型，待训练的参数，最后输出维度为10的结果\n",
    "        W = tf.Variable(tf.zeros([784, 10]), name='W')\n",
    "    with tf.name_scope('bias'):\n",
    "        #b是偏置项\n",
    "        b = tf.Variable(tf.zeros([10]),name='b')\n",
    "    with tf.name_scope('wx_plus_b'):\n",
    "        wx_plus_b = tf.matmul(x, W) + b\n",
    "    #模型输出结果\n",
    "    with tf.name_scope('softmax'):\n",
    "        prediction = tf.nn.softmax(wx_plus_b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. 定义损失函数\n",
    "一般softmax使用交叉损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据训练结果y和实际结果y_构造交叉熵损失\n",
    "cross_entropy = tf.reduce_mean(- tf.reduce_sum(y_ * tf.log(prediction)))\n",
    "# 二次损失\n",
    "# loss = tf.reduce_mean(tf.squre(y_ - y))\n",
    "#softmax交叉损失\n",
    "# cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y_, logits = y ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. 优化损失\n",
    "使用梯度下降法优化损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据损失，利用梯度下降法对模型的W,b进行优化\n",
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. 初始化操作\n",
    "只有在session中才能优化训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. 使用梯度下降，训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Testing Accuracy 0.9033\n",
      "Iter 1, Testing Accuracy 0.9178\n",
      "Iter 2, Testing Accuracy 0.9075\n",
      "Iter 3, Testing Accuracy 0.9052\n",
      "Iter 4, Testing Accuracy 0.915\n",
      "Iter 5, Testing Accuracy 0.9188\n",
      "Iter 6, Testing Accuracy 0.914\n",
      "Iter 7, Testing Accuracy 0.9203\n",
      "Iter 8, Testing Accuracy 0.9223\n",
      "Iter 9, Testing Accuracy 0.9213\n",
      "Iter 10, Testing Accuracy 0.9236\n",
      "Iter 11, Testing Accuracy 0.9201\n",
      "Iter 12, Testing Accuracy 0.8969\n",
      "Iter 13, Testing Accuracy 0.9164\n",
      "Iter 14, Testing Accuracy 0.926\n",
      "Iter 15, Testing Accuracy 0.923\n",
      "Iter 16, Testing Accuracy 0.9178\n",
      "Iter 17, Testing Accuracy 0.9211\n",
      "Iter 18, Testing Accuracy 0.9236\n",
      "Iter 19, Testing Accuracy 0.9216\n",
      "Iter 20, Testing Accuracy 0.9187\n",
      "Iter 21, Testing Accuracy 0.9212\n",
      "Iter 22, Testing Accuracy 0.9184\n",
      "Iter 23, Testing Accuracy 0.9201\n",
      "Iter 24, Testing Accuracy 0.921\n",
      "Iter 25, Testing Accuracy 0.925\n",
      "Iter 26, Testing Accuracy 0.9227\n",
      "Iter 27, Testing Accuracy 0.9197\n",
      "Iter 28, Testing Accuracy 0.9249\n",
      "Iter 29, Testing Accuracy 0.9196\n",
      "Iter 30, Testing Accuracy 0.9209\n",
      "Iter 31, Testing Accuracy 0.9223\n",
      "Iter 32, Testing Accuracy 0.9204\n",
      "Iter 33, Testing Accuracy 0.9238\n",
      "Iter 34, Testing Accuracy 0.92\n",
      "Iter 35, Testing Accuracy 0.9168\n",
      "Iter 36, Testing Accuracy 0.9221\n",
      "Iter 37, Testing Accuracy 0.9187\n",
      "Iter 38, Testing Accuracy 0.9184\n",
      "Iter 39, Testing Accuracy 0.9162\n",
      "Iter 40, Testing Accuracy 0.9191\n",
      "Iter 41, Testing Accuracy 0.9147\n",
      "Iter 42, Testing Accuracy 0.9222\n",
      "Iter 43, Testing Accuracy 0.9162\n",
      "Iter 44, Testing Accuracy 0.9216\n",
      "Iter 45, Testing Accuracy 0.9196\n",
      "Iter 46, Testing Accuracy 0.9189\n",
      "Iter 47, Testing Accuracy 0.9228\n",
      "Iter 48, Testing Accuracy 0.9154\n",
      "Iter 49, Testing Accuracy 0.9189\n",
      "Iter 50, Testing Accuracy 0.9159\n",
      "Iter 51, Testing Accuracy 0.9194\n",
      "Iter 52, Testing Accuracy 0.9191\n",
      "Iter 53, Testing Accuracy 0.9207\n",
      "Iter 54, Testing Accuracy 0.9214\n",
      "Iter 55, Testing Accuracy 0.9176\n",
      "Iter 56, Testing Accuracy 0.919\n",
      "Iter 57, Testing Accuracy 0.9235\n",
      "Iter 58, Testing Accuracy 0.9235\n",
      "Iter 59, Testing Accuracy 0.9166\n",
      "Iter 60, Testing Accuracy 0.9172\n",
      "Iter 61, Testing Accuracy 0.9226\n",
      "Iter 62, Testing Accuracy 0.9209\n",
      "Iter 63, Testing Accuracy 0.9152\n",
      "Iter 64, Testing Accuracy 0.9126\n",
      "Iter 65, Testing Accuracy 0.9163\n",
      "Iter 66, Testing Accuracy 0.9193\n",
      "Iter 67, Testing Accuracy 0.916\n",
      "Iter 68, Testing Accuracy 0.9233\n",
      "Iter 69, Testing Accuracy 0.9182\n",
      "Iter 70, Testing Accuracy 0.9154\n",
      "Iter 71, Testing Accuracy 0.9203\n",
      "Iter 72, Testing Accuracy 0.9214\n",
      "Iter 73, Testing Accuracy 0.921\n",
      "Iter 74, Testing Accuracy 0.9189\n",
      "Iter 75, Testing Accuracy 0.9111\n",
      "Iter 76, Testing Accuracy 0.9181\n",
      "Iter 77, Testing Accuracy 0.921\n",
      "Iter 78, Testing Accuracy 0.923\n",
      "Iter 79, Testing Accuracy 0.9167\n",
      "Iter 80, Testing Accuracy 0.9201\n",
      "Iter 81, Testing Accuracy 0.9178\n",
      "Iter 82, Testing Accuracy 0.9142\n",
      "Iter 83, Testing Accuracy 0.9185\n",
      "Iter 84, Testing Accuracy 0.9202\n",
      "Iter 85, Testing Accuracy 0.9181\n",
      "Iter 86, Testing Accuracy 0.9183\n",
      "Iter 87, Testing Accuracy 0.9179\n",
      "Iter 88, Testing Accuracy 0.9185\n",
      "Iter 89, Testing Accuracy 0.9201\n",
      "Iter 90, Testing Accuracy 0.9202\n",
      "Iter 91, Testing Accuracy 0.9232\n",
      "Iter 92, Testing Accuracy 0.9205\n",
      "Iter 93, Testing Accuracy 0.9208\n",
      "Iter 94, Testing Accuracy 0.9222\n",
      "Iter 95, Testing Accuracy 0.9202\n",
      "Iter 96, Testing Accuracy 0.9156\n",
      "Iter 97, Testing Accuracy 0.9206\n",
      "Iter 98, Testing Accuracy 0.9213\n",
      "Iter 99, Testing Accuracy 0.9217\n"
     ]
    }
   ],
   "source": [
    "#正确的预测结果\n",
    "correct_prediction = tf.equal(tf.argmax(prediction, 1), tf.argmax(y_, 1))\n",
    "#计算预测准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    #初始化相关变量\n",
    "    sess.run(init)\n",
    "    #添加tesorboard\n",
    "    write = tf.summary.FileWriter('logs/', sess.graph)\n",
    "    #1000步优化\n",
    "    for i in range(100):\n",
    "        for batch in range(n_batch):\n",
    "            #在mnist.train中取100个训练数据\n",
    "            #batch_xs是数据结构为(100,784)的图像数据，batch_ys是数据结构为(100,10)的实际标签数据\n",
    "            #batch_xs，batch_ys对应着两个占位符x,y_\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "            #在sess中运行train_step，运行时要传入占位符的值\n",
    "            sess.run(train_step, feed_dict={x:batch_xs, y_:batch_ys})\n",
    "        #获取最终准确率\n",
    "        acc = sess.run(accuracy, feed_dict={x:mnist.test.images, y_:mnist.test.labels})\n",
    "        print(\"Iter \" + str(i) + \", Testing Accuracy \" + str(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
