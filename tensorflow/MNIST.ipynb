{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 手写体识别\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data;\n",
    "#设置每一轮训练的batch\n",
    "batch_size = 100\n",
    "#设置初始学习率\n",
    "learning_rate = 0.8\n",
    "#学习率衰减\n",
    "learning_rate_decay = 0.999\n",
    "#最大训练步数\n",
    "max_steps = 30000\n",
    "\n",
    "#定义存储训练轮数的变量,其设置为不可训练类型，避免这个变量被计算滑动平均值\n",
    "training_step = tf.Variable(0,trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. 获取数据集合60000张图片,图片大小为28x28转化为一维数据后成784\n",
    "``` python\n",
    "train(train:55000+validation:5000) + test:10000\n",
    "mnist = train + validation + test\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /Users/aily/Downloads/文件/百度云/AI数据集合/mnist/train-images-idx3-ubyte.gz\n",
      "Extracting /Users/aily/Downloads/文件/百度云/AI数据集合/mnist/train-labels-idx1-ubyte.gz\n",
      "Extracting /Users/aily/Downloads/文件/百度云/AI数据集合/mnist/t10k-images-idx3-ubyte.gz\n",
      "Extracting /Users/aily/Downloads/文件/百度云/AI数据集合/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Training data and label size:\n",
      "(55000, 784) (55000, 10)\n",
      "Testing data and label size:\n",
      "(10000, 784) (10000, 10)\n",
      "Validating data and label size:\n",
      "(5000, 784) (5000, 10)\n",
      "Example training data [0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.3803922  0.37647063 0.3019608\n",
      " 0.46274513 0.2392157  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.3529412\n",
      " 0.5411765  0.9215687  0.9215687  0.9215687  0.9215687  0.9215687\n",
      " 0.9215687  0.9843138  0.9843138  0.9725491  0.9960785  0.9607844\n",
      " 0.9215687  0.74509805 0.08235294 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.54901963 0.9843138  0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.7411765  0.09019608 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.8862746  0.9960785  0.81568635 0.7803922  0.7803922  0.7803922\n",
      " 0.7803922  0.54509807 0.2392157  0.2392157  0.2392157  0.2392157\n",
      " 0.2392157  0.5019608  0.8705883  0.9960785  0.9960785  0.7411765\n",
      " 0.08235294 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.14901961 0.32156864\n",
      " 0.0509804  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.13333334 0.8352942  0.9960785  0.9960785  0.45098042 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.32941177\n",
      " 0.9960785  0.9960785  0.9176471  0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.32941177 0.9960785  0.9960785\n",
      " 0.9176471  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.4156863  0.6156863  0.9960785  0.9960785  0.95294124 0.20000002\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.09803922\n",
      " 0.45882356 0.8941177  0.8941177  0.8941177  0.9921569  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.94117653 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.26666668 0.4666667  0.86274517 0.9960785  0.9960785\n",
      " 0.9960785  0.9960785  0.9960785  0.9960785  0.9960785  0.9960785\n",
      " 0.9960785  0.5568628  0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.14509805 0.73333335 0.9921569\n",
      " 0.9960785  0.9960785  0.9960785  0.8745099  0.8078432  0.8078432\n",
      " 0.29411766 0.26666668 0.8431373  0.9960785  0.9960785  0.45882356\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.4431373  0.8588236  0.9960785  0.9490197  0.89019614 0.45098042\n",
      " 0.34901962 0.12156864 0.         0.         0.         0.\n",
      " 0.7843138  0.9960785  0.9450981  0.16078432 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.6627451  0.9960785\n",
      " 0.6901961  0.24313727 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.18823531 0.9058824  0.9960785\n",
      " 0.9176471  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.07058824 0.48627454 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.32941177 0.9960785  0.9960785  0.6509804  0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.54509807\n",
      " 0.9960785  0.9333334  0.22352943 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.8235295  0.9803922  0.9960785  0.65882355\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.9490197  0.9960785  0.93725497 0.22352943 0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.34901962 0.9843138  0.9450981\n",
      " 0.3372549  0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.01960784 0.8078432  0.96470594 0.6156863  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.01568628 0.45882356\n",
      " 0.27058825 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n",
      "Example label data [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/Users/aily/Downloads/文件/百度云/AI数据集合/mnist\",one_hot=True)\n",
    "print(\"Training data and label size:\")\n",
    "print(mnist.train.images.shape, mnist.train.labels.shape)\n",
    "print(\"Testing data and label size:\")\n",
    "print(mnist.test.images.shape, mnist.test.labels.shape)\n",
    "print(\"Validating data and label size:\")\n",
    "print(mnist.validation.images.shape, mnist.validation.labels.shape)\n",
    "print(\"Example training data\",mnist.train.images[0])\n",
    "print(\"Example label data\",mnist.train.labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. 定义隐藏层和输出层的前向传播方式，激活函数是relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hidden_layer(input_tensor, weight1, bias1, weight2, bias2, layer_name):\n",
    "    layer1 = tf.nn.relu(tf.matmul(input_tensor, weight1) + bias1)\n",
    "    layer2 = tf.nn.relu(tf.matmul(layer1, weight2) + bias2)\n",
    "    return layer2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "placeholder是占位符，相当于一个形参。只有在被调用时才分配内存单元,在调用结束时,就会释放出所分配的内存单元。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=(None, 784),name=\"x-input\")\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 10),name=\"y-output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. 定义权重参数和偏置参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成隐藏层参数其中weights包含784*500=392000个参数\n",
    "weight1 = tf.Variable(tf.truncated_normal([784,500],stddev=0.1))\n",
    "bias1 = tf.Variable(tf.constant(0.1, shape=[500]))\n",
    "\n",
    "#生成输出层参数，其中weight2包含500*10=5000个参数\n",
    "weight2 = tf.Variable(tf.truncated_normal([500,10],stddev=0.1))\n",
    "bias2 = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "\n",
    "#前向传播计算y值\n",
    "y = hidden_layer(x,weight1, bias1, weight2, bias2, 'y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.使用滑动平均方法更新隐藏层与输出层参数\n",
    "首先明确一点，TensorFlow中的ExponentialMovingAverage()是针对权重weight和偏差bias的，而不是针对训练集的。如果你现在训练集中实现这个效果，需要自己设计代码。 \n",
    "为什么要对w和b使用滑动平均模型呢？因为在神经网络中， \n",
    "更新的参数时候不能太大也不能太小，更新的参数跟你之前的参数有联系，不能发生突变。一旦训练的时候遇到个“疯狂”的参数，有了滑动平均模型，疯狂的参数就会被抑制下来，回到正常的队伍里。这种对于突变参数的抑制作用，用专业术语讲叫鲁棒性，鲁棒性就是对突变的抵抗能力，鲁棒性越好，这个模型对恶性参数的提抗能力就越强。 \n",
    "在TensorFlow中，ExponentialMovingAverage()可以传入两个参数：衰减率（decay）和数据的迭代次数（step），这里的decay和step分别对应我们的β和num_updates，所以在实现滑动平均模型的时候，步骤如下： \n",
    "- 1、定义训练轮数step \n",
    "- 2、然后定义滑动平均的类 \n",
    "- 3、给这个类指定需要用到滑动平均模型的变量（w和b） \n",
    "- 4、执行操作，把变量变为指数加权平均值\n",
    "\n",
    "[相关解释连接](https://blog.csdn.net/m0_38106113/article/details/81542863)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化一个滑动平均类，衰减率为0.99，为了在训练前期更新的更快，这里提供了num_updates,并设定了训练轮数\n",
    "averages_class = tf.train.ExponentialMovingAverage(0.99, training_step)\n",
    "\n",
    "#定义一个更新变量滑动平均值的操作，用tf.trainable_variable()获取所有可以训练的变量列表，也就是所有的w和b\n",
    "#也就是所有没有指定trainable_variables=False的参数\n",
    "averages_op = averages_class.apply(tf.trainable_variables())\n",
    "\n",
    "# 反向传播更新参数之后，再更新每一个参数的滑动平均值，计算y值\n",
    "average_y = hidden_layer(x, averages_class.average(weight1),\n",
    "                         averages_class.average(bias1),\n",
    "                         averages_class.average(weight2), \n",
    "                         averages_class.average(bias2), 'average_y' )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5. 计算损失(交叉熵)\n",
    "``` python\n",
    "softmax_cross_entropy_with_logits\n",
    "#可用于输入样本属于多类\n",
    "sparse_softmax_cross_entropy_with_logits\n",
    "#更适合输入样本只属于一类\n",
    "```\n",
    "[解释可见链接](https://blog.csdn.net/ZJRN1027/article/details/80199248 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#argmax(input, axis, name, dimension),用于计算每一个样例的预测答案，\n",
    "#其中input参数y是一个batch_size*10(batch_size行，10列)的二维数组，每\n",
    "#每一行表示一个样例前向传播的结果，axis=1表示选取最大值操作仅在第一个维度\n",
    "#中进行，即只在每一行选取最大值对应的下标，所以得到的是长度为batch_size\n",
    "#的一维数组，这个一维数组中的值就表示了每个样例对应的数字识别结果.\n",
    "#传入的logits为神经网络输出层的输出，shape为[batch_size，num_classes]，\n",
    "#传入的label为一个一维的vector，长度等于batch_size，每一个值的取值区间必\n",
    "#须是[0，num_classes)，其实每一个值就是代表了batch中对应样本的类别。\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, 1))\n",
    "#计算L2正则损失\n",
    "regularizer = tf.contrib.layers.l2_regularizer(0.0001)\n",
    "#计算模型正则化损失\n",
    "regularization = regularizer(weight1) + regularizer(weight2)\n",
    "#计算总损失\n",
    "loss = tf.reduce_mean(cross_entropy) + regularization\n",
    "#用指数衰减法设置学习率，这里staircase参数采用默认的false，即学习率连续衰减法\n",
    "learning_rate = tf.train.exponential_decay(learning_rate,\n",
    "                                           training_step,\n",
    "                                           mnist.train.num_examples/batch_size, \n",
    "                                           learning_rate_decay)\n",
    "#优化损失\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=training_step)\n",
    "#训练模型时既需要反向传播更新神经网络中的参数，也需更新每一个窗口的滑动平均值\n",
    "#以下两种做法都可以\n",
    "train_op = tf.group(train_step, averages_op)\n",
    "# with tf.control_dependencies([train_step, averages_op]):\n",
    "#     train_step = tf.no_op(name=\"train\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6. 检验数据，得出准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#检查使用了滑动平均值模型的神经网络前向传播是否正确\n",
    "#equal(X,y)对比每一维是否相同\n",
    "crorent_prediction = tf.equal(tf.argmax(average_y, 1), tf.argmax(y_, 1))\n",
    "#cast(x, DstT, name)这里用于将布尔型转换为float32，之后对float32求平均，就是正确率\n",
    "accuracy = tf.reduce_mean(tf.cast(crorent_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7. 创建会话开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 0 training steps, validation accuracy using average model is 9.44%\n",
      "After 1000 training steps, validation accuracy using average model is 9.44%\n",
      "After 2000 training steps, validation accuracy using average model is 18.96%\n",
      "After 3000 training steps, validation accuracy using average model is 18.52%\n",
      "After 4000 training steps, validation accuracy using average model is 17.78%\n",
      "After 5000 training steps, validation accuracy using average model is 9.58%\n",
      "After 6000 training steps, validation accuracy using average model is 8.68%\n",
      "After 7000 training steps, validation accuracy using average model is 16.14%\n",
      "After 8000 training steps, validation accuracy using average model is 11.26%\n",
      "After 9000 training steps, validation accuracy using average model is 9.58%\n",
      "After 10000 training steps, validation accuracy using average model is 9.58%\n",
      "After 11000 training steps, validation accuracy using average model is 9.58%\n",
      "After 12000 training steps, validation accuracy using average model is 9.58%\n",
      "After 13000 training steps, validation accuracy using average model is 9.58%\n",
      "After 14000 training steps, validation accuracy using average model is 9.58%\n",
      "After 15000 training steps, validation accuracy using average model is 9.58%\n",
      "After 16000 training steps, validation accuracy using average model is 9.58%\n",
      "After 17000 training steps, validation accuracy using average model is 9.58%\n",
      "After 18000 training steps, validation accuracy using average model is 9.58%\n",
      "After 19000 training steps, validation accuracy using average model is 9.58%\n",
      "After 20000 training steps, validation accuracy using average model is 9.58%\n",
      "After 21000 training steps, validation accuracy using average model is 9.58%\n",
      "After 22000 training steps, validation accuracy using average model is 9.58%\n",
      "After 23000 training steps, validation accuracy using average model is 9.58%\n",
      "After 24000 training steps, validation accuracy using average model is 9.58%\n",
      "After 25000 training steps, validation accuracy using average model is 9.58%\n",
      "After 26000 training steps, validation accuracy using average model is 9.58%\n",
      "After 27000 training steps, validation accuracy using average model is 9.58%\n",
      "After 28000 training steps, validation accuracy using average model is 9.58%\n",
      "After 29000 training steps, validation accuracy using average model is 9.58%\n",
      "After 30000 training steps, test accuracy using average model is 9.8%\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    #初始化变量\n",
    "    tf.global_variables_initializer().run()\n",
    "    #准备验证数据\n",
    "    validate_feed = {x:mnist.validation.images, y_:mnist.validation.labels}\n",
    "    #准备测试数据\n",
    "    test_feed = {x:mnist.test.images, y_:mnist.test.labels}\n",
    "    for i in range(max_steps):\n",
    "        if i % 1000 == 0:\n",
    "            #计算滑动平均在验证集结果，输出百分比结果\n",
    "            validate_accuracy = sess.run(accuracy, feed_dict=validate_feed)\n",
    "            print(\"After %d training steps, validation accuracy using average model is %g%%\"%(i, validate_accuracy * 100))\n",
    "            #一轮使用一个batch的训练数据，并进行训练input_data.read_data_sets()函数提供了train.next\n",
    "            xs,ys = mnist.train.next_batch(batch_size = 100)\n",
    "            sess.run(train_op, feed_dict={x:xs,y_:ys})\n",
    "    #检验最终正确率\n",
    "    test_accuracy = sess.run(accuracy, feed_dict = test_feed)\n",
    "    print(\"After %d training steps, test accuracy using average model is %g%%\"%(max_steps, test_accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3",
   "language": "python",
   "name": "py3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
